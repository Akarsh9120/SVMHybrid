{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eH3w7iLY4t4xu4d-Cdxgz437h4W0YC2S",
      "authorship_tag": "ABX9TyNFh6IxWzU+8QvRtkozx1g5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akarsh9120/SVMHybrid/blob/main/SVM_and_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLjIbeci8nMP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.util import random_noise\n",
        "\n",
        "# Load and preprocess the data without text removal\n",
        "Categories = ['cars', 'Ice cream cone', 'Cricket ball'] #the categories name should match with the folder names\n",
        "image_size = (150, 150)\n",
        "datadir = '/content/drive/MyDrive/Dataset' #Load all the datasets in the google drive if running on colab or any folder on the system and mention the relative path of it here..\n",
        "images = []\n",
        "targets = []\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def preprocess_images(datadir, image_size):\n",
        "    for category in Categories:\n",
        "        path = os.path.join(datadir, category)\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Warning: Directory '{path}' does not exist.\")\n",
        "            continue\n",
        "        for img_name in os.listdir(path):\n",
        "            if img_name.endswith('.png'):  # Filter out PNG images\n",
        "                img_path = os.path.join(path, img_name)\n",
        "                try:\n",
        "                    img_array = imread(img_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image '{img_path}': {e}\")\n",
        "                    continue\n",
        "\n",
        "                # RGBA images to RGB\n",
        "                if img_array.ndim == 3 and img_array.shape[2] == 4:\n",
        "                    img_array = img_array[:, :, :3]  # Keep only RGB channels\n",
        "\n",
        "                # to ensure image is in the correct format\n",
        "                img_array = img_array.astype(np.uint8)\n",
        "\n",
        "                img_resized = resize(img_array, image_size)\n",
        "                if img_resized.shape == (150, 150, 3):  # To Check if the image has the correct dimensions\n",
        "                    images.append(img_resized)\n",
        "                    targets.append(Categories.index(category))\n",
        "                else:\n",
        "                    print(f\"Ignored image {img_name} in category {category} due to incorrect dimensions: {img_resized.shape}\")\n",
        "\n",
        "# Load and preprocess images\n",
        "preprocess_images(datadir, image_size)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "targets = np.array(targets)\n",
        "\n",
        "if len(images) == 0:\n",
        "    print(\"Error: No images were loaded. Please check the data directory.\")\n",
        "    exit()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, targets, test_size=0.20, random_state=77, stratify=targets)\n",
        "\n",
        "# add more random noise to images\n",
        "def add_more_noise(images, var=0.1):\n",
        "    noisy_images = []\n",
        "    for image in images:\n",
        "        noisy_image = random_noise(image, var=var)\n",
        "        noisy_images.append(noisy_image)\n",
        "    return np.array(noisy_images)\n",
        "\n",
        "x_train_more_noisy = add_more_noise(x_train)\n",
        "x_test_more_noisy = add_more_noise(x_test)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# CNN model architecture\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(512, activation='relu'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(len(Categories), activation='softmax'))\n",
        "model_cnn.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# early stopping for CNN model\n",
        "early_stopping_cnn = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train CNN model with early stopping and data augmentation on more noisy images\n",
        "history_cnn_more_noisy = model_cnn.fit(datagen.flow(x_train_more_noisy, y_train, batch_size=32), epochs=25, validation_data=(x_test_more_noisy, y_test), callbacks=[early_stopping_cnn])\n",
        "\n",
        "# Train SVM model using CNN features from more noisy images\n",
        "features_train_more_noisy = model_cnn.predict(x_train_more_noisy)\n",
        "features_test_more_noisy = model_cnn.predict(x_test_more_noisy)\n",
        "\n",
        "# Adjust SVM hyperparameters\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.0001, 0.001, 0.1, 1], 'kernel': ['rbf', 'poly']}\n",
        "svc = svm.SVC(probability=True)\n",
        "model_svm = GridSearchCV(svc, param_grid, cv=5)\n",
        "model_svm.fit(features_train_more_noisy, y_train)\n",
        "\n",
        "# Combining both models for prediction\n",
        "random_index = random.randint(0, len(x_test) - 1)\n",
        "random_image = x_test[random_index]\n",
        "random_image_feature = model_cnn.predict(np.expand_dims(random_image, axis=0))\n",
        "svm_prediction = model_svm.predict(random_image_feature)\n",
        "cnn_prediction = np.argmax(model_cnn.predict(np.expand_dims(random_image, axis=0)))\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(random_image)\n",
        "plt.title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "# Print the predicted image class for CNN and SVM\n",
        "for i, category in enumerate(Categories):\n",
        "    print(f\"{category} =\", random_image_feature[0][i] * 100, \"%\")\n",
        "print(\"The predicted image is:\", Categories[cnn_prediction])\n",
        "\n",
        "\n",
        "#The execution time of this is 10 minutes please relax have a great day.\n"
      ]
    }
  ]
}